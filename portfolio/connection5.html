<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Mijn Portfolio</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="CSS/pf.css">
    <script src="pf.js"></script>

</head>


<body>
    <header>
        <nav>
       <div id="navbar2">
       <ul>
       <li><a href="index.html">HOME</a></li>
       <li><a href="start.html">SMART START</a></li>
       <li><a href="business.html">SMART BUSINESS</a></li>
       <li class="current"><a href="connection.html">SMART CONNECTION</a></li>
       <li><a href="technology.html">SMART TECHNOLOGY</a></li>
       <li><a href="project.html">SMART PROJECT</a></li>
       </ul>
       </div>
      </nav>
     </div>
</header>

    <section id= "main2">
        <article id="main-col2">
          <div id="main-title2">
             <h2>Hello World</h2>
           </div>
           <p>
               In deze les is gekeken naar een systeem dat voorwerpen herkent. Deze "Teachable Machine" van mij kan onderscheid maken tussen een appel en een pen.
               Op het moment dat u op "start" drukt en toestaat dat uw camera aangaat, kunt u de twee verschillende voorwerpen om beurten voor de camera houden. 
               Als u dan een appel in beeld houdt, zal de score van de appel het dichtst tegen de 1.00 aan gaan zitten. Bij de pen is dit natuurlijk andersom en geldt de hogere score voor de pen.
               Wel is aan te raden dat u een neutrale achtergrond gebruikt, zodat er geen afleidingen zijn. U hoeft dus zelf niet met uw gezicht in beeld, het voorwerp alleen is genoeg.
           </p>

    <div><h3>Teachable Machine Image Model</h3></div>
<button type="button" onclick="init()">Start</button>
<div id="webcam-container"></div>
<div id="label-container"></div>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/k1QkJE34-/";




    let model, webcam, labelContainer, maxPredictions;

    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    }
</script>



</article>

</section>


</body>
</html>

           <br><br>

           <a href="connection.html" class="go-back-btn"><i class="fa fa-home"></i> Ga terug naar 'Smart Connection'</a>
           
           <a href="connection4.html" class="go-back-btn">Ga terug naar vorige pagina</a>